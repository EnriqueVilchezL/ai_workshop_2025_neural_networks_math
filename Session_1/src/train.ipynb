{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.activation import *\n",
    "from network.layer import *\n",
    "from network.loss import *\n",
    "from network.optimizer import *\n",
    "from network.sequential import *\n",
    "from network.metric import *\n",
    "\n",
    "import numpy as np\n",
    "import mnist.mnist as mnist\n",
    "\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    model: Sequential,\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    Y_val: np.ndarray,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    optimizer: Optimizer,\n",
    "    loss_function: Loss,\n",
    "    metric_function : Metric\n",
    ") -> None:\n",
    "    shuffled_indexes = np.random.permutation(len(X))\n",
    "    X = X[shuffled_indexes]\n",
    "    Y = Y[shuffled_indexes]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        metric = 0\n",
    "        batches_steps = range(0, len(X), batch_size)\n",
    "        total_steps = len(batches_steps)\n",
    "\n",
    "        for i in batches_steps:\n",
    "            x_batch = X[i:i+batch_size]\n",
    "            y_batch = Y[i:i+batch_size]\n",
    "            \n",
    "\t\t\t\t\t\t# Forward pass\n",
    "            y_hat = model.forward({'X' : x_batch})\n",
    "\t\t\t\t\t\t# Compute loss\n",
    "            batch_loss = loss_function.forward({'Y' : y_batch, 'Y_hat' : y_hat})\n",
    "            batch_metric = metric_function.compute({'Y' : y_batch, 'Y_hat' : y_hat})\n",
    "            # Compute gradients\n",
    "            loss_function.backward()\n",
    "\t\t\t\t\t\t# Backward pass\n",
    "            model.backward({'dY' : loss_function.gradients['dY_hat']})\n",
    "\t\t\t\t\t\t# Update parameters\n",
    "            optimizer.update(model)\n",
    "\t\t\t\t\t\t# Accumulate batch loss mean\n",
    "            loss += batch_loss.mean()\n",
    "            metric += batch_metric\n",
    "        \n",
    "        y_hat = model.forward({'X': X_val})\n",
    "        val_loss = loss_function.forward({'Y': Y_val, 'Y_hat': y_hat}).mean()\n",
    "        val_metric = metric_function.compute({'Y': Y_val, 'Y_hat': y_hat})\n",
    "\n",
    "        \n",
    "        print(f\"Train ==> Epoch {epoch+1}/{epochs} loss: {loss/total_steps} accuracy: {metric/total_steps}\")\n",
    "        print(f\"Validation ==> Epoch {epoch+1}/{epochs} loss: {val_loss} accuracy: {val_metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ==> Epoch 1/100 loss: 1.8432929935052578 accuracy: 0.3154817430703625\n",
      "Validation ==> Epoch 1/100 loss: 0.6600128183583741 accuracy: 0.7962\n",
      "Train ==> Epoch 2/100 loss: 0.5306899705457799 accuracy: 0.8410680970149254\n",
      "Validation ==> Epoch 2/100 loss: 0.3627925822811711 accuracy: 0.8943\n",
      "Train ==> Epoch 3/100 loss: 0.31385531090210644 accuracy: 0.9094649520255863\n",
      "Validation ==> Epoch 3/100 loss: 0.2476188152067784 accuracy: 0.9275\n",
      "Train ==> Epoch 4/100 loss: 0.22334185268392037 accuracy: 0.935717617270789\n",
      "Validation ==> Epoch 4/100 loss: 0.1920679292779632 accuracy: 0.9436\n",
      "Train ==> Epoch 5/100 loss: 0.17426181721179218 accuracy: 0.9499933368869936\n",
      "Validation ==> Epoch 5/100 loss: 0.15855112654500286 accuracy: 0.9537\n",
      "Train ==> Epoch 6/100 loss: 0.14458567766623695 accuracy: 0.9582889125799574\n",
      "Validation ==> Epoch 6/100 loss: 0.14020652179012613 accuracy: 0.9583\n",
      "Train ==> Epoch 7/100 loss: 0.12442974151068335 accuracy: 0.9642190831556503\n",
      "Validation ==> Epoch 7/100 loss: 0.1298986572037486 accuracy: 0.9611\n",
      "Train ==> Epoch 8/100 loss: 0.10917607431207628 accuracy: 0.9686000799573561\n",
      "Validation ==> Epoch 8/100 loss: 0.1224494510519552 accuracy: 0.9624\n",
      "Train ==> Epoch 9/100 loss: 0.09685517792453735 accuracy: 0.9723314232409381\n",
      "Validation ==> Epoch 9/100 loss: 0.11711249688532269 accuracy: 0.9651\n",
      "Train ==> Epoch 10/100 loss: 0.08675755041504066 accuracy: 0.9750133262260128\n",
      "Validation ==> Epoch 10/100 loss: 0.11391167045017055 accuracy: 0.9662\n",
      "Train ==> Epoch 11/100 loss: 0.07850246175423968 accuracy: 0.9774786780383795\n",
      "Validation ==> Epoch 11/100 loss: 0.11182047784470157 accuracy: 0.9675\n",
      "Train ==> Epoch 12/100 loss: 0.07129485236769705 accuracy: 0.9794109808102346\n",
      "Validation ==> Epoch 12/100 loss: 0.11046072823197094 accuracy: 0.968\n",
      "Train ==> Epoch 13/100 loss: 0.06498854174895671 accuracy: 0.9814432302771855\n",
      "Validation ==> Epoch 13/100 loss: 0.10924787425020868 accuracy: 0.9681\n",
      "Train ==> Epoch 14/100 loss: 0.05940957543070951 accuracy: 0.9832089552238806\n",
      "Validation ==> Epoch 14/100 loss: 0.10888379251849965 accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "# Load mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load('mnist/mnist.pkl')\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# Add an extra dimension\n",
    "y_test = np.eye(10)[y_test].squeeze()\n",
    "y_train = np.eye(10)[y_train].squeeze()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(784, 64),\n",
    "    ReLU(),\n",
    "    Dense(64, 64),\n",
    "    ReLU(),\n",
    "    Dense(64, 10),\n",
    "\t\tSoftmax()\n",
    "])\n",
    "\n",
    "optimizer = StoichasticGradientDescent(learning_rate=0.001)\n",
    "loss = CategoricalCrossEntropy()\n",
    "metric = Accuracy()\n",
    "\n",
    "try:\n",
    "\ttrain(model, x_train, y_train, x_test, y_test, 100, 64, optimizer, loss, metric)\n",
    "\tmodel.save(\"model.pkl\")\n",
    "except KeyboardInterrupt:\n",
    "\tmodel.save(\"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
