{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.activation import *\n",
    "from network.layer import *\n",
    "from network.loss import *\n",
    "from network.optimizer import *\n",
    "from network.sequential import *\n",
    "import numpy as np\n",
    "import mnist.mnist as mnist\n",
    "\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    model: Sequential,\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    Y_val: np.ndarray,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    optimizer: Optimizer,\n",
    "    loss_function: Loss\n",
    ") -> None:\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        batches_steps = range(0, len(X), batch_size)\n",
    "        total_steps = len(batches_steps)\n",
    "\n",
    "        shuffled_indexes = np.random.permutation(len(X))\n",
    "        X = X[shuffled_indexes]\n",
    "        Y = Y[shuffled_indexes]\n",
    "\n",
    "        for i in batches_steps:\n",
    "            x_batch = X[i:i+batch_size]\n",
    "            y_batch = Y[i:i+batch_size]\n",
    "            \n",
    "\t\t\t\t\t\t# Forward pass\n",
    "\t\t\t\t\t\t# Compute loss\n",
    "            # Compute gradients\n",
    "\t\t\t\t\t\t# Backward pass\n",
    "\t\t\t\t\t\t# Update parameters\n",
    "\t\t\t\t\t\t# Accumulate batch loss mean\n",
    "        \n",
    "        y_hat = model.forward({'X': X_val})\n",
    "        val_loss = loss_function.forward({'Y': Y_val, 'Y_hat': y_hat})\n",
    "        val_loss = val_loss.mean()\n",
    "        \n",
    "        print(f\"Train ==> Epoch {epoch+1}/{epochs} loss: {loss/total_steps}\")\n",
    "        print(f\"Validation ==> Epoch {epoch+1}/{epochs} loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load('mnist/mnist.pkl')\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# Add an extra dimension\n",
    "y_test = np.eye(10)[y_test].squeeze()\n",
    "y_train = np.eye(10)[y_train].squeeze()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(784, 256),\n",
    "    ReLU(),\n",
    "    Dense(256, 256),\n",
    "    ReLU(),\n",
    "    Dense(256, 10),\n",
    "\t\tSoftmax()\n",
    "])\n",
    "\n",
    "optimizer = StoichasticGradientDescent(learning_rate=0.001)\n",
    "loss = MeanSquaredError()\n",
    "\n",
    "try:\n",
    "\ttrain(model, x_train, y_train, x_test, y_test, 10, 64, optimizer, loss)\n",
    "\tmodel.save(\"model.pkl\")\n",
    "except KeyboardInterrupt:\n",
    "\tmodel.save(\"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
