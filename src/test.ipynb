{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Neural Network\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/EnriqueVilchezL/ai_workshop_2025_neural_networks_math/blob/main/src/test.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "Neural networks are powerful machine learning models inspired by the human brain. They are widely used for tasks such as image recognition, natural language processing, and pattern detection. Testing a neural network involves getting a test dataset and use it to know if the model has a good generalization.\n",
    "\n",
    "In this workshop, we will test a neural network using the MNIST dataset, a collection of handwritten digits. We will go through the essential steps required to test a pretrained neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Modules and Initial Configuration\n",
    "\n",
    "The necessary libraries are imported to build and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/EnriqueVilchezL/ai_workshop_2025_neural_networks_math\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ai_workshop_2025_neural_networks_math/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.activation import *\n",
    "from network.layer import *\n",
    "from network.loss import *\n",
    "from network.optimizer import *\n",
    "from network.sequential import *\n",
    "from network.metric import *\n",
    "import numpy as np\n",
    "import mnist.mnist as mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the Testing Function\n",
    "\n",
    "The function responsible for testing the model using the testing dataset is defined. This function performs the following tasks:\n",
    "- Splits data into batches.\n",
    "- Performs forward propagation.\n",
    "- Computes loss and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model : Sequential,\n",
    "    X : np.ndarray,\n",
    "    Y : np.ndarray,\n",
    "    batch_size : int,\n",
    "    loss_function : Loss,\n",
    "    metric_function : Metric\n",
    "    ) -> None:\n",
    "\n",
    "        loss = 0\n",
    "        metric = 0\n",
    "\n",
    "        batches_steps = range(0, len(X), batch_size)\n",
    "        total_steps = len(batches_steps)\n",
    "\n",
    "        shuffled_indexes = np.random.permutation(len(X))\n",
    "        X = X[shuffled_indexes]\n",
    "        Y = Y[shuffled_indexes]\n",
    "        for i in batches_steps:\n",
    "            x_batch = X[i:i+batch_size]\n",
    "            y_batch = Y[i:i+batch_size]\n",
    "\n",
    "            y_hat = model.forward({'X' : x_batch})\n",
    "\n",
    "            batch_loss = loss_function.forward({'Y' : y_batch, 'Y_hat' : y_hat})\n",
    "            batch_metric = metric_function.compute({'Y' : y_batch, 'Y_hat' : y_hat})\n",
    "            \n",
    "            loss += batch_loss.mean()\n",
    "            metric += batch_metric\n",
    "\n",
    "        print(f\"Test ==> Loss: {loss/total_steps} accuracy: {metric/total_steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Model Configuration\n",
    "\n",
    "In this section, the MNIST dataset is loaded and values are normalized. Additionally, the neural network is loaded from a file that contains a pretrained neural network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist\n",
    "_, _, x_test, y_test = mnist.load('mnist/mnist.pkl')\n",
    "\n",
    "# Normalize data\n",
    "x_test = x_test / 255\n",
    "# Add an extra dimension\n",
    "y_test = np.eye(10)[y_test].squeeze()\n",
    "\n",
    "model = Sequential.load(\"model.pkl\")\n",
    "loss = CategoricalCrossEntropy()\n",
    "metric = Accuracy()\n",
    "test(model, x_test, y_test, 64, loss, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
